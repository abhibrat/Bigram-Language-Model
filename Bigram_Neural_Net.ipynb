{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlfHmLQbcR44DYSOXpPbFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhibrat/Bigram-Language-Model/blob/main/Bigram_Neural_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6_P2xWp0qV5",
        "outputId": "ef25f67b-7af1-4b52-de31-b1381defc148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(sorted(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.']=0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "whHYmlel1Wzk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "_pCmY5RvmTYv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = []\n",
        "ys = []\n",
        "for w in words[:1]:\n",
        "  chars = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chars, chars[1:]):\n",
        "    idx1 = stoi[ch1]\n",
        "    idx2 = stoi[ch2]\n",
        "\n",
        "    xs.append(idx1)\n",
        "    ys.append(idx2)\n",
        "\n",
        "    print(ch1, ch2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P5rx7RvnwDn",
        "outputId": "072ea8fd-32ab-41c7-c230-bded983de972"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". e\n",
            "e m\n",
            "m m\n",
            "m a\n",
            "a .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "WxNwknkjs7Dc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float()"
      ],
      "metadata": {
        "id": "JlghTUcuuY3W"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn([27,27])\n",
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHJBZc7Pmc9K",
        "outputId": "ed25b553-5d5b-4d61-9355-e1f04efbd31e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs6al_B7vz5M",
        "outputId": "e3f8d467-6f4b-42e7-9a9a-17d39b31eae0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1659, -0.3569, -2.2936, -0.3436,  0.2283, -0.7734, -1.0048, -0.1006,\n",
              "         0.0287, -0.7943,  0.5693,  1.1133,  0.0396, -0.7899,  0.6077,  0.5158,\n",
              "        -0.6399,  0.8918,  1.4564,  1.6335, -0.2923, -0.1900,  0.4007, -2.0067,\n",
              "        -2.1143, -0.1030, -0.2867])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = xenc @ W\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNn-taAWv6qE",
        "outputId": "8df0694e-a091-4b02-f4ac-0235229e4639"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1659, -0.3569, -2.2936, -0.3436,  0.2283, -0.7734, -1.0048, -0.1006,\n",
              "          0.0287, -0.7943,  0.5693,  1.1133,  0.0396, -0.7899,  0.6077,  0.5158,\n",
              "         -0.6399,  0.8918,  1.4564,  1.6335, -0.2923, -0.1900,  0.4007, -2.0067,\n",
              "         -2.1143, -0.1030, -0.2867],\n",
              "        [-0.1192, -0.0891,  0.2304,  1.3833, -0.1218, -0.5129, -0.2321,  1.2575,\n",
              "          0.2231, -0.8001, -0.3109, -0.8796,  2.0067, -0.7737,  2.2341, -0.5573,\n",
              "         -1.2147,  0.7093, -1.8323, -0.2658, -2.1418, -1.0662,  0.0774,  1.5379,\n",
              "          1.0650,  0.7472,  1.4222],\n",
              "        [ 0.3978,  0.0080, -0.0043, -0.0834, -2.0472, -0.4544,  0.9618, -0.7746,\n",
              "          0.5157,  0.7805, -0.6160,  1.1989, -0.3088,  0.6144, -1.3606,  1.3996,\n",
              "         -0.8041,  1.1498, -1.4748,  0.0264, -0.9099,  0.2048, -0.5033, -0.4294,\n",
              "          0.4746,  0.9195, -0.4502],\n",
              "        [ 0.3978,  0.0080, -0.0043, -0.0834, -2.0472, -0.4544,  0.9618, -0.7746,\n",
              "          0.5157,  0.7805, -0.6160,  1.1989, -0.3088,  0.6144, -1.3606,  1.3996,\n",
              "         -0.8041,  1.1498, -1.4748,  0.0264, -0.9099,  0.2048, -0.5033, -0.4294,\n",
              "          0.4746,  0.9195, -0.4502],\n",
              "        [-1.2358, -0.4040, -0.4897,  0.7210,  1.0416, -0.7894, -0.6545, -1.5646,\n",
              "         -0.0353,  0.4035,  2.3670, -0.8293,  1.4265, -1.3619, -0.3458, -0.4362,\n",
              "         -1.4635,  0.5056,  0.7876, -0.4541,  1.0490,  0.2225, -0.5730,  0.7803,\n",
              "         -2.1385,  0.0475, -0.0093]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "_HG-NeCRxI6u"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0wezumAxc4E",
        "outputId": "ae300e0c-62cd-4883-c450-92df76002e0a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = probs[torch.arange(5), ys]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08-D88-g0IvG",
        "outputId": "f29ae85b-a924-4a87-8a6b-bfcbaaf3d4eb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0136, 0.0089, 0.0523, 0.0285, 0.0071])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKiS9Rn_1FNU",
        "outputId": "619a9bab-2383-4e0a-ec45-d3eff79a2996"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  idx1 = xs[i].item()\n",
        "  idx2 = ys[i].item()\n",
        "  print(f'Bigram example {i+1}: {itos[idx1]} {itos[idx2]}')\n",
        "  p = probs[i,idx2]\n",
        "  print(f'Probability of label: {itos[idx2]} --> {p}')\n",
        "  log_likelihood = p.log()\n",
        "  print(f'{log_likelihood=}')\n",
        "  negative_log_likelihood = -log_likelihood\n",
        "  print(f'{negative_log_likelihood=}')\n",
        "  nlls[i] = negative_log_likelihood\n",
        "\n",
        "print('======')\n",
        "print('Average negative log likelihood i.e loss = ', nlls.mean().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZVY1dau2p9-",
        "outputId": "80263458-ab12-4648-edc9-465da577b315"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram example 1: . e\n",
            "Probability of label: e --> 0.013572633266448975\n",
            "log_likelihood=tensor(-4.2997)\n",
            "negative_log_likelihood=tensor(4.2997)\n",
            "Bigram example 2: e m\n",
            "Probability of label: m --> 0.008852507919073105\n",
            "log_likelihood=tensor(-4.7271)\n",
            "negative_log_likelihood=tensor(4.7271)\n",
            "Bigram example 3: m m\n",
            "Probability of label: m --> 0.0522775799036026\n",
            "log_likelihood=tensor(-2.9512)\n",
            "negative_log_likelihood=tensor(2.9512)\n",
            "Bigram example 4: m a\n",
            "Probability of label: a --> 0.028507491573691368\n",
            "log_likelihood=tensor(-3.5576)\n",
            "negative_log_likelihood=tensor(3.5576)\n",
            "Bigram example 5: a .\n",
            "Probability of label: . --> 0.007137717213481665\n",
            "log_likelihood=tensor(-4.9424)\n",
            "negative_log_likelihood=tensor(4.9424)\n",
            "======\n",
            "Average negative log likelihood i.e loss =  4.095578193664551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "ziiVR2S55zbw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts/counts.sum(1, keepdim=True)\n",
        "loss = -probs[torch.arange(5), ys].log().mean()\n",
        "loss.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUvk2yLM6nXe",
        "outputId": "54a5c1b1-03bf-4ea0-ce41-2a61229e51de"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2870)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad = None\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "9ez6Mmwe7eZk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.data += -1 * W.grad"
      ],
      "metadata": {
        "id": "b8gITuP_7-mN"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output after training on the first word\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  idx = 0\n",
        "  while True:\n",
        "    x_enc = F.one_hot(torch.tensor(idx), num_classes=27).float()\n",
        "    # print(f'{x_enc=}')\n",
        "    logits = x_enc @ W\n",
        "    counts = logits.exp()\n",
        "    # print(f'{counts=}')\n",
        "    probs = counts/counts.sum()\n",
        "\n",
        "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[idx])\n",
        "    if idx == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n8I4Br_-VGE",
        "outputId": "65c52416-f906-4697-851c-f6ef6bec4c76"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ema.\n",
            "emma.\n",
            "ema.\n",
            "emmmma.\n",
            "emmmma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Considering all words\n",
        "\n",
        "# Preapare dataset\n",
        "xs = []\n",
        "ys = []\n",
        "for w in words:\n",
        "  chars = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chars, chars[1:]):\n",
        "    idx1 = stoi[ch1]\n",
        "    idx2 = stoi[ch2]\n",
        "\n",
        "    xs.append(idx1)\n",
        "    ys.append(idx2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('Number of elements: ', num)\n",
        "\n",
        "#Input to the neuron\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "\n",
        "# Initialize neuron weights\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJZJmj0IBtX1",
        "outputId": "3e8b7439-a230-42b6-ceb1-e2e0e05e1c08"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation before training\n",
        "for i in range(20):\n",
        "  out = []\n",
        "  idx = 0\n",
        "  while True:\n",
        "    x_enc = F.one_hot(torch.tensor(idx), num_classes=27).float()\n",
        "    # print(f'{x_enc=}')\n",
        "    logits = x_enc @ W\n",
        "    counts = logits.exp()\n",
        "    # print(f'{counts=}')\n",
        "    probs = counts/counts.sum()\n",
        "\n",
        "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[idx])\n",
        "    if idx == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di9mDGOcHKHr",
        "outputId": "cda7b387-0fd3-45cc-f49c-71c4cca186a8"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yofvwqjkdktcnblz.\n",
            "yw.\n",
            "ovrzwchmbqdaydgqfbmhqpouywytozbzwzrzqrdj.\n",
            "ytdkkv.\n",
            "ztsmltgpcxtikfblqnsastwzhtc.\n",
            "onmkisedqppxwwluxin.\n",
            "yddlpfkdjjljagkzisifbwfbjmcnbyguiaxwvyyg.\n",
            "dphbjmhyqsedtoziszhksufzwytkadicmoufbmwmpqqfbmrddjucvknikatviyxvtjxhufblt.\n",
            "ttjbmafplwgmhgqbpokalv.\n",
            "pxbqrilpuslpalphhuxh.\n",
            "ozwwchufphkwmgpcjieaklwmhdztphphqdtiarincszrmbzt.\n",
            "andjufoufaumktwgwpvkfr.\n",
            "zwtkt.\n",
            "ozitdpsicxgkokdwcpfbqaomyhpchyddfbc.\n",
            "s.\n",
            "phkvm.\n",
            "ekt.\n",
            "gmdtkpafrciirhcgksxralpjzxszwtrmhusbmkdajdglpchuszfpoalmbmpejmfjbgluzoztduepxtjszxepxxekkmgwxerzxr.\n",
            "tkc.\n",
            "t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for i in range(50):\n",
        "  # Forward Pass\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts/counts.sum(1, keepdim=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean()\n",
        "  print(loss.data.item())\n",
        "\n",
        "  # Backprop\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # Gradient Descent\n",
        "  W.data += -10 * W.grad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w_2oTseCZ55",
        "outputId": "e806ac70-6d25-46dd-a22d-b4f8a4ec7702"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1797327995300293\n",
            "3.147189140319824\n",
            "3.117339849472046\n",
            "3.0898513793945312\n",
            "3.064443349838257\n",
            "3.0408785343170166\n",
            "3.0189592838287354\n",
            "2.998518705368042\n",
            "2.9794163703918457\n",
            "2.961529493331909\n",
            "2.9447529315948486\n",
            "2.928992509841919\n",
            "2.9141643047332764\n",
            "2.900193929672241\n",
            "2.887012481689453\n",
            "2.874558448791504\n",
            "2.862776279449463\n",
            "2.851613998413086\n",
            "2.841024160385132\n",
            "2.830965757369995\n",
            "2.8213977813720703\n",
            "2.812286138534546\n",
            "2.8035967350006104\n",
            "2.7953009605407715\n",
            "2.7873711585998535\n",
            "2.7797818183898926\n",
            "2.7725107669830322\n",
            "2.7655372619628906\n",
            "2.7588419914245605\n",
            "2.7524075508117676\n",
            "2.7462172508239746\n",
            "2.7402572631835938\n",
            "2.7345142364501953\n",
            "2.7289750576019287\n",
            "2.7236287593841553\n",
            "2.7184643745422363\n",
            "2.713472366333008\n",
            "2.708644151687622\n",
            "2.7039716243743896\n",
            "2.699446678161621\n",
            "2.695061683654785\n",
            "2.6908113956451416\n",
            "2.6866886615753174\n",
            "2.682687759399414\n",
            "2.678804397583008\n",
            "2.675032138824463\n",
            "2.671367883682251\n",
            "2.6678061485290527\n",
            "2.6643431186676025\n",
            "2.6609747409820557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation after training\n",
        "for i in range(20):\n",
        "  out = []\n",
        "  idx = 0\n",
        "  while True:\n",
        "    x_enc = F.one_hot(torch.tensor(idx), num_classes=27).float()\n",
        "    # print(f'{x_enc=}')\n",
        "    logits = x_enc @ W\n",
        "    counts = logits.exp()\n",
        "    # print(f'{counts=}')\n",
        "    probs = counts/counts.sum()\n",
        "\n",
        "    idx = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[idx])\n",
        "    if idx == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nGcrUMDFVMz",
        "outputId": "ac994ccc-a7fc-49af-f235-11108e27145b"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mxtrabyna.\n",
            "bjanaiech.\n",
            "kiken.\n",
            "shan.\n",
            "so.\n",
            "kadyly.\n",
            "zaisionch.\n",
            "ti.\n",
            "sh.\n",
            "gfinahaxatana.\n",
            "em.\n",
            "kesaleyna.\n",
            "aran.\n",
            "lioen.\n",
            "erorraror.\n",
            "jennlowonnde.\n",
            "anien.\n",
            "jade.\n",
            "jon.\n",
            "dastan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with regularization\n",
        "for i in range(10):\n",
        "  # Forward Pass\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts/counts.sum(1, keepdim=True)\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.data.item())\n",
        "\n",
        "  # Backprop\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # Gradient Descent\n",
        "  W.data += -1 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IS8s5txHpQ6",
        "outputId": "4616bcdc-75d5-4119-a4cb-713144fe170a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4913740158081055\n",
            "2.491368293762207\n",
            "2.491363286972046\n",
            "2.4913580417633057\n",
            "2.4913527965545654\n",
            "2.491346836090088\n",
            "2.4913418292999268\n",
            "2.4913365840911865\n",
            "2.4913313388824463\n",
            "2.491325616836548\n"
          ]
        }
      ]
    }
  ]
}